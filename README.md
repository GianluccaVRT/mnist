# UNICAMP - Projeto

## Redes Neurais - MNIST

Devemos implementar uma rede neural regularizada com uma camada escondida. Queremos observar a quantidade de imagens classificadas corretamente e observar aquelas imagens classificadas incorretamente, junstamente com o dígito correto. Devemos, também, implementar o algoritmo de checagem do gradiente para nosso backpropagation (reduzindo a rede, devido ao custo computacional). 
Feito isso, devemos implementar a mesma rede regularizada, mas agora utilizando o gradiente conjugado.
Por fim, devemos separar os exemplos em 3 conjuntos: treino, validação e teste. Sugere-se 60% para treino, 20% para validação e 20% para teste. Com isso, poderemos observar o erro de treino da rede neural regularizada. Também será possível gerar uma curva de aprendizado. Por fim, devemos automatizar o processo de escolhar do valor de λ (usando o conceito de conjunto de validação para isso) e calcular o erro de teste para este λ ótimo encontrado.

Resultados do projeto estão no arquivo 
